# AI Tutor Environment Configuration
# Copy this file to .env and fill in your values

# ==========================================
# LLM Provider Selection
# ==========================================

# Choose your LLM provider: 'openai', 'ollama_local', or 'ollama_remote'
LLM_PROVIDER=openai

# ==========================================
# OpenAI API Configuration
# ==========================================
# (Only required if LLM_PROVIDER=openai)

# Your OpenAI API key (get it from https://platform.openai.com/api-keys)
OPENAI_API_KEY=your-api-key-here

# OpenAI models to use
# Valid chat models: gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo
OPENAI_CHAT_MODEL=gpt-4o-mini
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# ==========================================
# Ollama Configuration
# ==========================================
# (Required if LLM_PROVIDER=ollama_local or ollama_remote)

# Local Ollama instance URL (default: http://localhost:11434)
OLLAMA_LOCAL_URL=http://localhost:11434

# Remote Ollama instance URL (required if LLM_PROVIDER=ollama_remote)
OLLAMA_REMOTE_URL=

# Ollama API key (if your remote instance requires authentication)
OLLAMA_API_KEY=

# Ollama models to use
OLLAMA_CHAT_MODEL=llama3.1:8b
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# Ollama request timeout in seconds
OLLAMA_TIMEOUT=120

# ==========================================
# Knowledge Base Configuration
# ==========================================

# Directory containing your course materials
KB_DIR=kb

# Output file for the knowledge base index
KB_INDEX_FILE=kb_index.json

# Text chunking settings
CHUNK_SIZE=900
CHUNK_OVERLAP=150

# Number of knowledge base chunks to retrieve for each query
CONTEXT_CHUNKS=6

# ==========================================
# Server Configuration
# ==========================================

# Server host and port
HOST=0.0.0.0
PORT=8000

# Maximum conversation turns to keep in memory (per session)
MAX_TURNS=12

# Session cookie name
SESSION_COOKIE_NAME=tutor_session_id

# ==========================================
# Logging Configuration
# ==========================================

# Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Directory for logs
LOG_DIR=logs

# Consented chat log filename
CONSENT_LOG_FILE=consented_chats.jsonl

# Server log filename
SERVER_LOG_FILE=tutor_server.log

# ==========================================
# System Prompt (Optional)
# ==========================================

# Path to a custom system prompt file (leave empty to use default)
# SYSTEM_PROMPT_FILE=prompts/custom_tutor_prompt.txt
